{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# load .env\n",
    "load_dotenv()\n",
    "\n",
    "# retrieve env variables\n",
    "qwen_api_key = os.getenv('QWEN_API_KEY')\n",
    "qwen_openai_sdk_base_url = os.getenv('QWEN_OPENAI_SDK_BASE_URL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是阿里云的智能助手，专注于提供关于阿里云产品和服务的信息。虽然我的主要专长不是Spark SQL，但我可以提供一些基本指导和信息。如果你有关于Spark SQL的具体问题或需要帮助，请告诉我！\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "            api_key=qwen_api_key, \n",
    "            base_url=qwen_openai_sdk_base_url,\n",
    "        )\n",
    "completion = client.chat.completions.create(\n",
    "            model='qwen-turbo',\n",
    "            messages=[\n",
    "                {'role': 'system', 'content': \"\"\"You are a Spark SQL expert.\"\"\"},\n",
    "                {'role': 'user', 'content': '你是谁'}],\n",
    "            temperature=0.1,\n",
    "            )\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m pip install -i https://mirrors.aliyun.com/pypi/simple/ openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Calculate Logic from source data to target result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "def read_spark_sql_source_code(filePath):\n",
    "\n",
    "    # logging config\n",
    "    logging.basicConfig(level=logging.ERROR, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    if os.path.exists(filePath): \n",
    "        with open(filePath, 'r') as file:\n",
    "            code = file.read()\n",
    "    else:\n",
    "        logging.error(f'{filePath} does not exist, please check it again!')\n",
    "        code = ''\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_table_from_spark_sql(SQL:str, llm_model:str='qwen2.5-72b-instruct'):\n",
    "    import os\n",
    "    import re\n",
    "    from openai import OpenAI\n",
    "    \n",
    "    msg = f\"\"\"Spark SQL Code: ```{SQL}```\n",
    "    requirements:\n",
    "    1. Give the result in the Json format.\n",
    "        the json contains 'spark_data_lineage`, which is a list containing\n",
    "        `target_result`: targe result table name or file name,\n",
    "        `source_data`: the list of table names or source file names used to get the target result , \n",
    "        `transformation`: the calculation steps show how `target_result` is calculated from the `source_data`. \n",
    "                                The step should be a description sentence including operation/transformation and the dataframe/table/view involved\n",
    "                                take care of the column match.\n",
    "    2. Consider the input data from DB or files as `source_data`. consider the calcaluted data that is shown to user or saved as the `target_result`.\n",
    "    3. The intermediate view or table or dataframe cannot be views as `source_data`.\n",
    "    4. Give the json result only.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = OpenAI(\n",
    "            api_key=qwen_api_key, \n",
    "            base_url=qwen_openai_sdk_base_url,\n",
    "        )\n",
    "        completion = client.chat.completions.create(\n",
    "            model=llm_model,\n",
    "            messages=[\n",
    "                {'role': 'system', 'content': 'You are a Spark SQL expert. Given a Spark SQL, please help user to identify the datasource and target result and analize the calculation logic from datasource to targe result'},\n",
    "                {'role': 'user', 'content': msg}],\n",
    "            )\n",
    "        pattern = r'```json(.*?)```'\n",
    "\n",
    "        matches = re.findall(pattern, completion.choices[0].message.content, re.DOTALL)\n",
    "        return matches[0]\n",
    "    except:\n",
    "        return \"```json\\n\\n```\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "  \"spark_data_lineage\": [\n",
      "    {\n",
      "      \"target_result\": \"result_table1\",\n",
      "      \"source_data\": [\"datas/agent.log\"],\n",
      "      \"transformation\": [\n",
      "        \"Read the data from 'datas/agent.log' and split each line into three columns (t1, t2, t3).\",\n",
      "        \"Filter the rows where the value in column t2 is even.\",\n",
      "        \"Create a DataFrame df1 with the filtered data and define the schema (t1: StringType, t2: IntegerType, t3: IntegerType).\",\n",
      "        \"Register df1 as a temporary view 't'.\",\n",
      "        \"Execute SQL query to select all columns from view 't' and add a new column 'tp' with a constant value 'r'.\",\n",
      "        \"The result of the SQL query is stored in DataFrame result_table1.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"target_result\": \"result_table2\",\n",
      "      \"source_data\": [\"datas/agent.log\"],\n",
      "      \"transformation\": [\n",
      "        \"Read the data from 'datas/agent.log' and split each line into three columns (t1, t2, t3).\",\n",
      "        \"Filter the rows where the value in column t3 is even.\",\n",
      "        \"Create a DataFrame df2 with the filtered data and define the schema (r1: StringType, r2: IntegerType, r3: IntegerType).\",\n",
      "        \"Register df2 as a temporary view 'r'.\",\n",
      "        \"Execute SQL query to select all columns from view 'r' and add a new column 'tp' with a constant value 'r'.\",\n",
      "        \"The result of the SQL query is stored in DataFrame result_table2.\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "code = read_spark_sql_source_code('./data/spark_sql_1.txt')\n",
    "result = extract_table_from_spark_sql(code, llm_model='qwen2.5-72b-instruct')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the Difference between two data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_spark_code_difference(original_sql_lineage:str, revised_sql_lineage:str, llm_model:str='qwen2.5-72b-instruct'):\n",
    "    import os\n",
    "    import re\n",
    "    from openai import OpenAI\n",
    "    \n",
    "    msg = f\"\"\"\n",
    "    Original Spark SQL Code Data Lineage: ```{original_sql_lineage}```\n",
    "    Revised Spark SQL Code Data Lineage: ```{revised_sql_lineage}```\n",
    "\n",
    "    requirements:\n",
    "    1. Give the result in the Json format. Skip irrelated calculation steps.\n",
    "        the json contains 'spark_data_lineage`, which is a list containing\n",
    "        `original_target_result`: targe result table name or file name of the original spark code,\n",
    "        `original_source_data`: the list of table names or source file names used to get the target result,\n",
    "        `revised_target_result`: targe result table name or file name of the revised spark code,\n",
    "        `revised_source_data`: targe result table name or file name of the revised spark code,\n",
    "        `transformation_logic_change`:show the difference between the `original_target_result` and `original_target_result`. And explain why they differs by listing the changes in the transformation process. Show the differences only.\n",
    "    2. Consider the input data from DB or files as source_data. consider the calcaluted data that is shown to user or saved as the target_result.\n",
    "    3. The intermediate view or table or dataframe cannot be views as source_data.\n",
    "    4. Give the json result only\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = OpenAI(\n",
    "            api_key=qwen_api_key, \n",
    "            base_url=qwen_openai_sdk_base_url,\n",
    "        )\n",
    "        completion = client.chat.completions.create(\n",
    "            model=llm_model,\n",
    "            messages=[\n",
    "                {'role': 'system', 'content': \"\"\"You are a Spark SQL expert. \n",
    "                 Given two data lineages from two Spark SQLs, one is `Original Spark SQL Code Data Lineage`, the other one is `Revised Spark SQL Code Data Lineage`, \n",
    "                 Please help user to identify the changes between these two spark sql code data lineages.\n",
    "                 The changes include the change of ```source_data``` and ```target_result``` and ```transformation_logic```\"\"\"},\n",
    "                {'role': 'user', 'content': msg}],\n",
    "            )\n",
    "        pattern = r'```json(.*?)```'\n",
    "\n",
    "        matches = re.findall(pattern, completion.choices[0].message.content, re.DOTALL)\n",
    "        return matches[0]\n",
    "    except:\n",
    "        return \"```json\\n\\n```\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm_model = 'qwen2.5-72b-instruct'\n",
    "code_before = read_spark_sql_source_code('./data/spark_sql_before_1.txt')\n",
    "code_after = read_spark_sql_source_code('./data/spark_sql_after_1.txt')\n",
    "result = compare_spark_code_difference(code_before, code_after, llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "  \"spark_data_lineage\": [\n",
      "    {\n",
      "      \"original_target_result\": \"result_table1\",\n",
      "      \"original_source_data\": [\"datas/agent.log\"],\n",
      "      \"revised_target_result\": \"result_table2\",\n",
      "      \"revised_source_data\": [\"datas/agent.log\"],\n",
      "      \"transformation_logic_change\": {\n",
      "        \"original_transformation\": \"rowRDD.filter(row => row.getInt(1) % 2 == 0)\",\n",
      "        \"revised_transformation\": \"rowRDD.filter(row => row.getInt(2) % 2 == 0)\",\n",
      "        \"difference\": \"The filter condition has changed from filtering rows where the second column (t2) is even to filtering rows where the third column (t3) is even.\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_spark_code_difference(original_sql_lineage:str, revised_sql_lineage:str, llm_model:str='qwen2.5-72b-instruct'):\n",
    "    import os\n",
    "    import re\n",
    "    from openai import OpenAI\n",
    "    \n",
    "    msg = f\"\"\"\n",
    "    Original Spark SQL Code Data Lineage: ```{original_sql_lineage}```\n",
    "    Revised Spark SQL Code Data Lineage: ```{revised_sql_lineage}```\n",
    "\n",
    "    requirements:\n",
    "    1. Give the result in the Json format.\n",
    "        the json contains 'spark_data_lineage`, which is a list containing\n",
    "        `original_target_result`: targe result table name or file name of the original spark code,\n",
    "        `original_source_data`: the list of table names or source file names used to get the target result,\n",
    "        `revised_target_result`: targe result table name or file name of the revised spark code,\n",
    "        `revised_source_data`: targe result table name or file name of the revised spark code,\n",
    "        `transformation_logic_change`: show the difference between the `original_target_result` and `original_target_result`. And explain why they differs by listing the changes in the transformation process. Only show the differences.\n",
    "    2. Give the json result only \"\"\"\n",
    "    try:\n",
    "        client = OpenAI(\n",
    "            api_key=qwen_api_key, \n",
    "            base_url=qwen_openai_sdk_base_url,\n",
    "        )\n",
    "        completion = client.chat.completions.create(\n",
    "            model=llm_model,\n",
    "            messages=[\n",
    "                {'role': 'system', 'content': \"\"\"You are a Spark SQL expert. \n",
    "                 Given two data lineages from two Spark SQLs, one is `Original Spark SQL Code Data Lineage`, the other one is `Revised Spark SQL Code Data Lineage`, \n",
    "                 Please help user to identify the changes between these two spark sql code data lineages.\n",
    "                 The changes include the change of ```source_data``` and ```target_result``` and ```transformation_logic```\"\"\"},\n",
    "                {'role': 'user', 'content': msg}],\n",
    "            )\n",
    "        pattern = r'```json(.*?)```'\n",
    "\n",
    "        matches = re.findall(pattern, completion.choices[0].message.content, re.DOTALL)\n",
    "        return matches[0]\n",
    "    except:\n",
    "        return \"```json\\n\\n```\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = 'qwen-turbo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "  \"spark_data_lineage\": [\n",
      "    {\n",
      "      \"target_result\": \"result_table1\",\n",
      "      \"source_data\": [\"datas/agent.log\"],\n",
      "      \"transformation\": [\n",
      "        \"Read data from datas/agent.log into an RDD\",\n",
      "        \"Filter rows where t2 is even and create DataFrame df1 with columns t1, t2, t3\",\n",
      "        \"Create a temporary view 't' from df1\",\n",
      "        \"Select all columns from view 't' and add a new column 'tp' with value 'r'\",\n",
      "        \"The final result is stored in result_table1\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "code_before = read_spark_sql_source_code('./data/spark_sql_before_1.txt')\n",
    "data_lineage_before = extract_table_from_spark_sql(code_before,llm_model)\n",
    "print(data_lineage_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "  \"spark_data_lineage\": [\n",
      "    {\n",
      "      \"target_result\": \"result_table2\",\n",
      "      \"source_data\": [\"datas/agent.log\"],\n",
      "      \"transformation\": [\n",
      "        \"Read data from datas/agent.log into an RDD named rowRDD\",\n",
      "        \"Filter rows from rowRDD where r3 (third column) is even and create a new RDD named tableRDD2\",\n",
      "        \"Create a DataFrame named df2 from tableRDD2 with schema (r1, r2, r3)\",\n",
      "        \"Create a temporary view named r from df2\",\n",
      "        \"Select columns r1, r2, r3 from r and add a new column tp with value 'r'\",\n",
      "        \"The final result is stored in the DataFrame named result_table2\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "code_after = read_spark_sql_source_code('./data/spark_sql_after_1.txt')\n",
    "data_lineage_after = extract_table_from_spark_sql(code_after, llm_model)\n",
    "print(data_lineage_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "  \"spark_data_lineage\": [\n",
      "    {\n",
      "      \"original_target_result\": \"result_table1\",\n",
      "      \"original_source_data\": [\"datas/agent.log\"],\n",
      "      \"revised_target_result\": \"result_table2\",\n",
      "      \"revised_source_data\": [\"datas/agent.log\"],\n",
      "      \"transformation_logic_change\": [\n",
      "        \"The transformation logic differs in the following ways:\",\n",
      "        \"- The original code filters rows where t2 is even, while the revised code filters rows where r3 is even.\",\n",
      "        \"- The original code uses columns t1, t2, t3, while the revised code uses columns r1, r2, r3.\",\n",
      "        \"- The original code creates a temporary view named 't', while the revised code creates a temporary view named 'r'.\",\n",
      "        \"- The final result is stored in different tables: result_table1 vs result_table2.\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = compare_spark_code_difference(data_lineage_before, data_lineage_after, llm_model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon_alibaba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
