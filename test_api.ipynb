{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Extract Lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Tables: \n",
      "{\n",
      "  \"spark_data_lineage\": [\n",
      "    {\n",
      "      \"target_result\": \"result_table1\",\n",
      "      \"source_data\": [\"datas/agent.log\"],\n",
      "      \"transformation\": [\n",
      "        \"Read the log file 'datas/agent.log' and split each line into three columns (t1, t2, t3) to create an RDD of Rows.\",\n",
      "        \"Filter the RDD to keep only rows where the value in column t2 is even, creating tableRDD1.\",\n",
      "        \"Convert tableRDD1 into a DataFrame df1 with schema (t1: StringType, t2: IntegerType, t3: IntegerType).\",\n",
      "        \"Register df1 as a temporary view 't'.\",\n",
      "        \"Execute SQL query to select all columns from view 't' and add a new column 'tp' with a constant value 'r', creating result_table1.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"target_result\": \"result_table2\",\n",
      "      \"source_data\": [\"datas/agent.log\"],\n",
      "      \"transformation\": [\n",
      "        \"Read the log file 'datas/agent.log' and split each line into three columns (t1, t2, t3) to create an RDD of Rows.\",\n",
      "        \"Filter the RDD to keep only rows where the value in column t3 is even, creating tableRDD2.\",\n",
      "        \"Convert tableRDD2 into a DataFrame df2 with schema (r1: StringType, r2: IntegerType, r3: IntegerType).\",\n",
      "        \"Register df2 as a temporary view 'r'.\",\n",
      "        \"Execute SQL query to select all columns from view 'r' and add a new column 'tp' with a constant value 'r', creating result_table2.\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "from test_lib.help import read_spark_sql_source_code\n",
    "\n",
    "# Define the API endpoint\n",
    "url = 'http://127.0.0.1:5000/extract_data_lineage'\n",
    "\n",
    "# Define the payload (input data)\n",
    "\n",
    "SQL =  read_spark_sql_source_code('./data/spark_sql_1.txt')\n",
    "payload = {\n",
    "    \"SQL\": SQL\n",
    "}\n",
    "\n",
    "# Optionally, you can specify the LLM model\n",
    "payload['llm_model'] = 'qwen2.5-72b-instruct' # 'qwen2.5-72b-instruct'\n",
    "\n",
    "# Convert the payload to JSON format\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "# Send the POST request\n",
    "response = requests.post(url, data=json.dumps(payload), headers=headers)\n",
    "\n",
    "# Check the response status code\n",
    "if response.status_code == 200:\n",
    "    # Parse the JSON response\n",
    "    result = response.json()\n",
    "    print(\"Extracted Tables:\", result['result'])\n",
    "else:\n",
    "    print(\"Failed to extract tables. Status code:\", response.status_code)\n",
    "    print(\"Response:\", response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Result: \n",
      "{\n",
      "  \"spark_data_lineage\": [\n",
      "    {\n",
      "      \"original_target_result\": \"result_table1\",\n",
      "      \"original_source_data\": [\"datas/agent.log\"],\n",
      "      \"revised_target_result\": \"result_table2\",\n",
      "      \"revised_source_data\": [\"datas/agent.log\"],\n",
      "      \"transformation_change\": [\n",
      "        \"change 1: In the original code, the `tableRDD1` is created by filtering rows where `row.getInt(1) % 2 == 0`. In the revised code, this filter is commented out and `tableRDD2` is created by filtering rows where `row.getInt(2) % 2 == 0`.\",\n",
      "        \"change 2: In the original code, `df1` is created from `tableRDD1` and registered as a temporary view `t`. In the revised code, `df1` is commented out and `df2` is created from `tableRDD2` and registered as a temporary view `r`.\",\n",
      "        \"change 3: In the original code, the SQL query selects data from the temporary view `t`. In the revised code, the SQL query selects data from the temporary view `r`.\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Define the API endpoint\n",
    "url = 'http://127.0.0.1:5000/compare_spark_code'\n",
    "\n",
    "# Define the payload (input data)\n",
    "code_before = read_spark_sql_source_code('./data/spark_sql_before_1.txt')\n",
    "code_after = read_spark_sql_source_code('./data/spark_sql_after_1.txt')\n",
    "\n",
    "payload = {\n",
    "    \"original_sql_code\": code_before,\n",
    "    \"revised_sql_code\": code_after \n",
    "}\n",
    "\n",
    "# Optionally, you can specify the LLM model\n",
    "payload['llm_model'] = 'qwen2.5-72b-instruct' # 'qwen2.5-72b-instruct'\n",
    "\n",
    "# Convert the payload to JSON format\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "# Send the POST request\n",
    "response = requests.post(url, data=json.dumps(payload), headers=headers)\n",
    "\n",
    "# Check the response status code\n",
    "if response.status_code == 200:\n",
    "    # Parse the JSON response\n",
    "    result = response.json()\n",
    "    print(\"Comparison Result:\", result['result'])\n",
    "else:\n",
    "    print(\"Failed to compare SQL lineages. Status code:\", response.status_code)\n",
    "    print(\"Response:\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Result: \n",
      "{\n",
      "  \"tables\": {\n",
      "    \"row_unchanged_table\": [],\n",
      "    \"row_changed_table\": [\"student\"],\n",
      "    \"created_table\": [\"student_bucket\"],\n",
      "    \"deleted_table\": [\"employeetable\"]\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Define the API endpoint\n",
    "url = 'http://127.0.0.1:5000/list_table_from_spark_code'\n",
    "\n",
    "# Define the payload (input data)\n",
    "code = \"\"\"\n",
    "CREATE TABLE student_bucket\n",
    "    USING parquet\n",
    "    CLUSTERED BY (id) INTO 4 buckets (\n",
    "    WITH tmpTable AS (\n",
    "        SELECT * FROM student WHERE id > 100\n",
    "    )\n",
    "    SELECT * FROM tmpTable\n",
    ");\n",
    "\n",
    "DROP TABLE employeetable;\n",
    "\"\"\"\n",
    "\n",
    "payload = {\n",
    "    \"spark_sql_code\": code\n",
    "}\n",
    "\n",
    "# Optionally, you can specify the LLM model\n",
    "payload['llm_model'] = 'qwen2.5-72b-instruct' # 'qwen2.5-72b-instruct'\n",
    "\n",
    "# Convert the payload to JSON format\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "# Send the POST request\n",
    "response = requests.post(url, data=json.dumps(payload), headers=headers)\n",
    "\n",
    "# Check the response status code\n",
    "if response.status_code == 200:\n",
    "    # Parse the JSON response\n",
    "    result = response.json()\n",
    "    print(\"Comparison Result:\", result['result'])\n",
    "else:\n",
    "    print(\"Failed to compare SQL lineages. Status code:\", response.status_code)\n",
    "    print(\"Response:\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon_alibaba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
